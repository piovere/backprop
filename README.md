# backprop

Trying to implement a neural network trained by backpropagation from scratch. 
I think I understand the math, but I am doing this to prove it to myself.

## Plan

1. Single-layer network with working training
2. One hidden layer
3. Arbitrary number of layers
4. *There is no number 4*
5. Fiddle around with activation functions

## TODO

- [ ] Whole-network prediction
- [ ] Documentation!
- [ ] Test coverage
- [ ] Deployment
